import streamlit as st
import pandas as pd
import numpy as np
import xgboost as xgb
import plotly.express as px
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import plotly.graph_objects as go
from sklearn.metrics import confusion_matrix, classification_report
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    filename='app.log.txt'
)

class analysis:
    @staticmethod
    def load_data():
        """Carga los datos procesados desde session_state."""
        try:
            logging.info("Iniciando carga de datos desde 'data_final_estandarizado.csv'")
            file_path = "data_final_estandarizado.csv"
            df = pd.read_csv(file_path)
            logging.info(f"Datos cargados exitosamente: {df.shape[0]} filas, {df.shape[1]} columnas")
            return df
        except FileNotFoundError:
            error_msg = "No se encontr√≥ el archivo 'data_final_estandarizado.csv' en la carpeta del c√≥digo"
            st.error(f"‚ùå {error_msg}.")
            logging.error(error_msg)
            return None
        except Exception as e:
            error_msg = f"Error al cargar los datos: {str(e)}"
            st.error(f"‚ùå {error_msg}")
            logging.error(error_msg)
            return None
        
    @staticmethod
    def train_model(X, y):
        """Entrena un modelo XGBoost con monitoreo de p√©rdida y manejo de excepciones."""
        logging.info("Iniciando entrenamiento del modelo XGBoost")
        
        if X.empty or y.empty:
            error_msg = "No hay suficientes datos para entrenar el modelo"
            st.error(f"‚ö†Ô∏è {error_msg}.")
            logging.error(error_msg)
            return None, None, (None, None, None)

        try:
            logging.info("Realizando divisi√≥n train-test")
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            logging.info(f"Divisi√≥n completada: X_train: {X_train.shape}, X_test: {X_test.shape}")
            
            logging.info("Inicializando modelo XGBClassifier")
            # Especificar eval_metric en la inicializaci√≥n en lugar de en fit()
            modelo = xgb.XGBClassifier(
                n_estimators=100, 
                learning_rate=0.1, 
                random_state=42,
                eval_metric="logloss"  # Colocar eval_metric aqu√≠, no en fit()
            )

            logging.info("Configurando conjunto de evaluaci√≥n")
            eval_set = [(X_train, y_train), (X_test, y_test)]
            
            logging.info("Iniciando entrenamiento del modelo")
            # Quitar eval_metric de fit() y usar solo eval_set
            modelo.fit(
                X_train, 
                y_train, 
                eval_set=eval_set, 
                verbose=False
            )
            logging.info("Entrenamiento del modelo completado exitosamente")

            logging.info("Obteniendo resultados de evaluaci√≥n")
            resultados = modelo.evals_result()
            
            logging.info("Generando predicciones en conjunto de prueba")
            y_pred = modelo.predict(X_test)
            logging.info(f"Predicciones generadas: {len(y_pred)} muestras")

            return modelo, resultados, (X_test, y_test, y_pred)
        except Exception as e:
            error_msg = f"Error durante el entrenamiento del modelo: {e}"
            st.error(f"‚ùå {error_msg}")
            logging.error(error_msg)
            return None, None, (None, None, None)

    @staticmethod
    def analyze_results(modelo, X_test, y_test):
        """Muestra m√©tricas del modelo con validaciones previas."""
        logging.info("Iniciando an√°lisis de resultados del modelo")
        
        if modelo is None or X_test is None or y_test is None:
            error_msg = "No se pueden analizar los resultados porque el modelo no se entren√≥ correctamente"
            st.error(f"‚ùå {error_msg}.")
            logging.error(error_msg)
            return

        try:
            logging.info("Calculando precisi√≥n del modelo")
            precision = modelo.score(X_test, y_test)
            logging.info(f"Precisi√≥n del modelo: {precision:.4f}")

            st.header("üìä An√°lisis de Resultados")
            if precision > 0.90:
                st.success(f"üåü Excelente rendimiento con una precisi√≥n de {precision:.2%}.")
                logging.info(f"Rendimiento excelente: precisi√≥n {precision:.2%}")
            elif 0.75 <= precision <= 0.90:
                st.info(f"‚úÖ Buen rendimiento con una precisi√≥n de {precision:.2%}.")
                logging.info(f"Rendimiento bueno: precisi√≥n {precision:.2%}")
            else:
                st.warning(f"‚ö†Ô∏è Precisi√≥n baja ({precision:.2%}). Considera revisar los datos y ajustar hiperpar√°metros.")
                logging.warning(f"Rendimiento bajo: precisi√≥n {precision:.2%}")
        except Exception as e:
            error_msg = f"Error al analizar resultados del modelo: {e}"
            st.error(f"‚ùå {error_msg}")
            logging.error(error_msg)

    @staticmethod
    def plot_loss(resultados):
        """Grafica la evoluci√≥n de la p√©rdida del modelo, con validaciones."""
        logging.info("Iniciando generaci√≥n de gr√°fica de p√©rdida")
        
        if not resultados or "validation_0" not in resultados:
            error_msg = "No hay resultados de entrenamiento disponibles para graficar la p√©rdida"
            st.error(f"‚ùå {error_msg}.")
            logging.error(error_msg)
            return

        try:
            st.header("üìâ Evoluci√≥n de la P√©rdida del Modelo")
            logging.info("Preparando datos para la gr√°fica de p√©rdida")
            
            # Plot training and validation loss
            logging.info("Creando figura Plotly para las curvas de p√©rdida")
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=list(range(len(resultados["validation_0"]["logloss"]))),
                y=resultados["validation_0"]["logloss"],
                mode='lines',
                name='Training Loss'
            ))
            fig.add_trace(go.Scatter(
                x=list(range(len(resultados["validation_1"]["logloss"]))),
                y=resultados["validation_1"]["logloss"],
                mode='lines',
                name='Validation Loss'
            ))
            fig.update_layout(
                title="Curva de P√©rdida en el Entrenamiento",
                xaxis_title="Iteraciones",
                yaxis_title="P√©rdida LogLoss"
            )
            logging.info("Mostrando gr√°fica de curva de p√©rdida")
            st.plotly_chart(fig)
            logging.info("Gr√°fica de p√©rdida generada y mostrada exitosamente")
        except Exception as e:
            error_msg = f"Error al generar gr√°fica de p√©rdida: {e}"
            st.error(f"‚ùå {error_msg}")
            logging.error(error_msg)

    @staticmethod
    def plot_feature_importance(modelo, X):
        """Muestra la importancia de las caracter√≠sticas con m√°s detalle."""
        logging.info("Iniciando visualizaci√≥n de importancia de caracter√≠sticas")
        
        if modelo is None or X is None:
            error_msg = "No se puede calcular la importancia de caracter√≠sticas"
            st.error(f"‚ùå {error_msg}.")
            logging.error(error_msg)
            return

        try:
            st.header("üîé Importancia de las Caracter√≠sticas")
            logging.info("Extrayendo importancia de caracter√≠sticas del modelo")
            
            # Get feature importance from model
            importancia = modelo.feature_importances_
            feature_names = X.columns
            logging.info(f"Obtenidas {len(importancia)} caracter√≠sticas con sus valores de importancia")
            
            # Create DataFrame for easier manipulation
            logging.info("Creando DataFrame de importancias")
            importance_df = pd.DataFrame({
                'Feature': feature_names,
                'Importance': importancia
            }).sort_values('Importance', ascending=False)
            
            # Create bar chart with Plotly
            logging.info("Generando gr√°fica de barras de importancia de caracter√≠sticas")
            fig = px.bar(
                importance_df,
                x='Importance', 
                y='Feature',
                orientation='h',
                title="Importancia de Caracter√≠sticas (ordenadas)",
                color='Importance',
                color_continuous_scale='Blues'
            )
            st.plotly_chart(fig)
            logging.info("Gr√°fica de importancia de caracter√≠sticas mostrada exitosamente")
            
            # Show table with actual values
            logging.info("Mostrando tabla de valores de importancia")
            st.subheader("Valores de Importancia")
            st.dataframe(importance_df)
            logging.info("Tabla de importancia de caracter√≠sticas mostrada exitosamente")
        except Exception as e:
            error_msg = f"Error al visualizar importancia de caracter√≠sticas: {e}"
            st.error(f"‚ùå {error_msg}")
            logging.error(error_msg)

    @staticmethod
    def plot_confusion_matrix(y_test, y_pred, df_original):
        """Muestra la matriz de confusi√≥n para evaluar el modelo."""
        logging.info("Iniciando generaci√≥n de matriz de confusi√≥n")
        
        if y_test is None or y_pred is None or df_original is None:
            error_msg = "Datos insuficientes para generar matriz de confusi√≥n"
            st.error(f"‚ùå {error_msg}.")
            logging.error(error_msg)
            return
            
        try:
            st.header("üß© Matriz de Confusi√≥n")
            
            # Get unique classes
            logging.info("Obteniendo clases √∫nicas para matriz de confusi√≥n")
            classes = df_original["Pais Destino"].unique()
            logging.info(f"Identificadas {len(classes)} clases √∫nicas")
            
            # Compute confusion matrix
            logging.info("Calculando matriz de confusi√≥n")
            cm = confusion_matrix(y_test, y_pred)
            
            # Normalize confusion matrix
            logging.info("Normalizando matriz de confusi√≥n")
            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
            
            # Create heatmap
            logging.info("Generando visualizaci√≥n de matriz de confusi√≥n")
            fig = px.imshow(
                cm_normalized,
                labels=dict(x="Predicci√≥n", y="Real", color="Proporci√≥n"),
                x=classes,
                y=classes,
                text_auto=True,
                color_continuous_scale="Blues"
            )
            fig.update_layout(title="Matriz de Confusi√≥n Normalizada")
            st.plotly_chart(fig)
            logging.info("Matriz de confusi√≥n mostrada exitosamente")
            
            # Show classification report
            logging.info("Generando reporte de clasificaci√≥n")
            st.subheader("Reporte de Clasificaci√≥n")
            report = classification_report(y_test, y_pred, target_names=classes, output_dict=True)
            report_df = pd.DataFrame(report).transpose()
            st.dataframe(report_df)
            logging.info("Reporte de clasificaci√≥n mostrado exitosamente")
        except Exception as e:
            error_msg = f"Error al generar matriz de confusi√≥n: {e}"
            st.error(f"‚ùå {error_msg}")
            logging.error(error_msg)

    @staticmethod
    def plot_predictions_distribution(y_test, y_pred, df_original):
        """Muestra un histograma de predicciones del modelo."""
        logging.info("Iniciando visualizaci√≥n de distribuci√≥n de predicciones")
        
        if y_test is None or y_pred is None or df_original is None:
            error_msg = "Datos insuficientes para visualizar distribuci√≥n de predicciones"
            st.error(f"‚ùå {error_msg}.")
            logging.error(error_msg)
            return
            
        try:
            st.header("üìä Distribuci√≥n de Predicciones")
            logging.info("Mapeando √≠ndices a nombres de pa√≠ses")

            # Map indices to actual country names
            classes = df_original["Pais Destino"].unique()
            y_test_names = [classes[i] for i in y_test]
            y_pred_names = [classes[i] for i in y_pred]
            
            logging.info("Creando DataFrame para visualizaci√≥n de predicciones")
            df_pred = pd.DataFrame({"Real": y_test_names, "Predicci√≥n": y_pred_names})
            
            # Distribution of predictions
            logging.info("Generando histograma de distribuci√≥n de predicciones")
            fig1 = px.histogram(
                df_pred,
                x="Predicci√≥n",
                title="Distribuci√≥n de Predicciones por Pa√≠s Destino",
                color="Predicci√≥n",
                color_discrete_sequence=px.colors.qualitative.Plotly
            )
            st.plotly_chart(fig1)
            logging.info("Histograma de predicciones mostrado exitosamente")
            
            # Accuracy by country
            logging.info("Calculando precisi√≥n por pa√≠s")
            st.subheader("Precisi√≥n por Pa√≠s")
            accuracy_by_country = df_pred.groupby("Real").apply(
                lambda x: (x["Real"] == x["Predicci√≥n"]).mean()
            ).reset_index(name="Precisi√≥n")
            
            logging.info("Generando gr√°fica de barras de precisi√≥n por pa√≠s")
            fig2 = px.bar(
                accuracy_by_country,
                x="Real",
                y="Precisi√≥n",
                title="Precisi√≥n del Modelo por Pa√≠s",
                color="Precisi√≥n",
                color_continuous_scale="RdYlGn"
            )
            st.plotly_chart(fig2)
            logging.info("Gr√°fica de precisi√≥n por pa√≠s mostrada exitosamente")
        except Exception as e:
            error_msg = f"Error al visualizar distribuci√≥n de predicciones: {e}"
            st.error(f"‚ùå {error_msg}")
            logging.error(error_msg)

    @staticmethod
    def feature_contribution(modelo, X_test, feature_names):
        """Visualiza la contribuci√≥n de caracter√≠sticas para ejemplos individuales."""
        logging.info("Iniciando an√°lisis de contribuci√≥n de caracter√≠sticas")
        
        if modelo is None or X_test is None or feature_names is None:
            error_msg = "Datos insuficientes para analizar contribuci√≥n de caracter√≠sticas"
            st.error(f"‚ùå {error_msg}.")
            logging.error(error_msg)
            return
            
        try:
            st.header("üîç Contribuci√≥n de Caracter√≠sticas (Muestra)")
            
            # Select a random sample to explain
            logging.info("Seleccionando muestras aleatorias para an√°lisis")
            if len(X_test) > 5:
                sample_indices = np.random.choice(len(X_test), 5, replace=False)
                logging.info(f"Seleccionadas 5 muestras aleatorias de {len(X_test)} disponibles")
            else:
                sample_indices = range(len(X_test))
                logging.info(f"Seleccionadas todas las {len(X_test)} muestras disponibles")
            
            for idx in sample_indices:
                logging.info(f"Analizando muestra #{idx+1}")
                sample = X_test.iloc[idx:idx+1]
                
                # Get the feature contributions for this prediction
                logging.info("Calculando contribuciones de caracter√≠sticas para la predicci√≥n")
                contribs = modelo.get_booster().predict(xgb.DMatrix(sample), pred_contribs=True)
                
                # The last column is the bias/base value, so we exclude it
                feature_contribs = contribs[0][:-1]
                
                # Create a DataFrame for visualization
                logging.info("Creando DataFrame para visualizaci√≥n de contribuciones")
                contrib_df = pd.DataFrame({
                    'Feature': feature_names,
                    'Contribution': feature_contribs
                }).sort_values('Contribution', ascending=False)
                
                st.subheader(f"Ejemplo #{idx+1}")
                
                # Display the sample values
                logging.info("Mostrando valores de caracter√≠sticas de la muestra")
                st.write("Valores de caracter√≠sticas:")
                sample_display = pd.DataFrame(sample.values, columns=feature_names)
                st.dataframe(sample_display)
                
                # Plot the contributions
                logging.info("Generando gr√°fica de contribuciones para la muestra")
                fig = px.bar(
                    contrib_df,
                    x='Contribution',
                    y='Feature',
                    orientation='h',
                    title=f"Contribuci√≥n de Caracter√≠sticas (Ejemplo #{idx+1})",
                    color='Contribution',
                    color_continuous_scale='RdBu',
                    color_continuous_midpoint=0
                )
                st.plotly_chart(fig)
                logging.info(f"An√°lisis de contribuci√≥n para muestra #{idx+1} completado exitosamente")
        except Exception as e:
            error_msg = f"Error al analizar contribuci√≥n de caracter√≠sticas: {e}"
            st.error(f"‚ùå {error_msg}")
            logging.error(error_msg)

    @staticmethod
    def show_results():
        """Ejecuta todas las funciones de an√°lisis y visualizaci√≥n."""
        logging.info("Iniciando proceso completo de an√°lisis y visualizaci√≥n")
        
        try:
            # Apply custom CSS
            logging.info("Aplicando estilos CSS personalizados")
            st.markdown("""
            <style>
                .custom-h3 {
                    color: #1E88E5;
                    font-size: 1.8rem;
                    text-align: center;
                }
                .custom-h4 {
                    color: #26A69A;
                    font-size: 1.4rem;
                }
            </style>
            """, unsafe_allow_html=True)
            
            st.markdown('<h3 class="custom-h3">Predicci√≥n de Destino de Exportaci√≥n de Fertilizantes üå±</h3>', unsafe_allow_html=True)
            logging.info("Iniciando carga de datos para an√°lisis")
            df = analysis.load_data()
            if df is None:
                logging.error("Proceso terminado: no se pudieron cargar los datos")
                return

            logging.info("Preparando datos para entrenamiento del modelo")
            X = df.drop(columns=["Pais Destino"])
            y = df["Pais Destino"]
            logging.info(f"Datos preparados: X: {X.shape}, y: {len(y)}")

            logging.info("Iniciando entrenamiento del modelo")
            modelo, resultados, (X_test, y_test, y_pred) = analysis.train_model(X, y)
            if modelo is None:
                logging.error("Proceso terminado: no se pudo entrenar el modelo")
                return

            logging.info("Ejecutando an√°lisis de resultados")
            analysis.analyze_results(modelo, X_test, y_test)
            
            logging.info("Generando visualizaci√≥n de curva de p√©rdida")
            analysis.plot_loss(resultados)
            
            logging.info("Analizando importancia de caracter√≠sticas")
            analysis.plot_feature_importance(modelo, X)
            
            logging.info("Generando matriz de confusi√≥n")
            analysis.plot_confusion_matrix(y_test, y_pred, df)
            
            logging.info("Analizando distribuci√≥n de predicciones")
            analysis.plot_predictions_distribution(y_test, y_pred, df)
            
            logging.info("Analizando contribuci√≥n de caracter√≠sticas")
            analysis.feature_contribution(modelo, X_test, X.columns)
            
            logging.info("Proceso completo de an√°lisis y visualizaci√≥n finalizado exitosamente")
        except Exception as e:
            error_msg = f"Error durante el proceso de an√°lisis: {e}"
            st.error(f"‚ùå {error_msg}")
            logging.error(error_msg)


class app:
    def run(self):
        """Funci√≥n principal para ejecutar la aplicaci√≥n sin main()"""
        logging.info("Iniciando aplicaci√≥n")
        
        try:
            # Apply custom CSS
            logging.info("Aplicando estilos CSS personalizados")
            st.markdown("""
            <style>
                .custom-h3 {
                    color: #1E88E5;
                    font-size: 1.8rem;
                    text-align: center;
                }
                .custom-h4 {
                    color: #26A69A;
                    font-size: 1.4rem;
                }
            </style>
            """, unsafe_allow_html=True)
            
            st.markdown('<h3 class="custom-h3">An√°lisis de Datos de Fertilizantes üå±</h3>', unsafe_allow_html=True)
            st.write("")
            
            # Use the static method from analysis class to load processed data
            logging.info("Cargando datos procesados")
            df = analysis.load_data()
            if df is None:
                logging.error("Aplicaci√≥n terminada: no se pudieron cargar los datos")
                return

            # Display information about the processed data
            logging.info("Verificando duplicados en los datos")
            duplicados_existentes = df.duplicated().sum() > 0
            logging.info(f"Duplicados encontrados: {df.duplicated().sum() if duplicados_existentes else 0}")
            
            logging.info("Mostrando muestra de datos")
            st.dataframe(df.head(6))
            st.write("")
            
            # Data summary
            logging.info("Generando resumen de datos")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Filas", df.shape[0])
            with col2:
                st.metric("Columnas", df.shape[1])
            with col3:
                nulos = df.isnull().sum().sum()
                st.metric("Valores nulos", nulos)
                logging.info(f"Resumen de datos: {df.shape[0]} filas, {df.shape[1]} columnas, {nulos} valores nulos")
                
            st.write(f"Duplicados: {'S√≠' if duplicados_existentes else 'No'}")
            
            # Backup the processed data
            if st.button("Respaldar datos"):
                logging.info("Iniciando respaldo de datos")
                try:
                    df.to_csv("backup_data_results.csv", index=False)
                    st.success("‚úÖ Datos respaldados en 'backup_data_results.csv'.")
                    logging.info("Datos respaldados exitosamente en 'backup_data_results.csv'")
                except Exception as e:
                    error_msg = f"Error al respaldar datos: {e}"
                    st.error(f"‚ùå {error_msg}")
                    logging.error(error_msg)
            
            st.write(" *********************** ")
            st.markdown('<h4 class="custom-h4">Limpieza de los datos üßπüìä</h4>', unsafe_allow_html=True)
            
            # Data cleaning options
            logging.info("Configurando opciones de limpieza de datos")
            cleaning_options = st.multiselect(
                "Seleccione opciones de limpieza:",
                ["Eliminar duplicados", "Eliminar valores nulos"],
                default=["Eliminar duplicados", "Eliminar valores nulos"] if duplicados_existentes or df.isnull().sum().sum() > 0 else []
            )
            logging.info(f"Opciones de limpieza seleccionadas: {cleaning_options}")
            
            # Clean data based on selected options
            df_limpio = df.copy()
            if "Eliminar duplicados" in cleaning_options and duplicados_existentes:
                logging.info("Eliminando filas duplicadas")
                filas_antes = df_limpio.shape[0]
                df_limpio = df_limpio.drop_duplicates()
                filas_eliminadas = filas_antes - df_limpio.shape[0]
                st.success(f"‚úÖ Se eliminaron {filas_eliminadas} filas duplicadas.")
                logging.info(f"Se eliminaron {filas_eliminadas} filas duplicadas")
                
            if "Eliminar valores nulos" in cleaning_options and df.isnull().sum().sum() > 0:
                logging.info("Eliminando valores nulos")
                nulos_antes = df_limpio.isnull().sum().sum()
                df_limpio = df_limpio.dropna()
                st.success(f"‚úÖ Se eliminaron {nulos_antes} valores nulos.")
                logging.info(f"Se eliminaron {nulos_antes} valores nulos")
            
            # Display cleaned data
            if len(cleaning_options) > 0:
                logging.info("Mostrando datos despu√©s de la limpieza")
                st.subheader("Datos despu√©s de la limpieza:")
                st.dataframe(df_limpio.head(6))
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Filas originales", df.shape[0])
                with col2:
                    st.metric("Filas despu√©s de limpieza", df_limpio.shape[0], 
                            delta=df_limpio.shape[0] - df.shape[0])
                logging.info(f"Datos despu√©s de limpieza: {df_limpio.shape[0]} filas, {df_limpio.shape[1]} columnas")
            
            # Save cleaned data to session state
            logging.info("Guardando datos en session_state")
            if len(cleaning_options) > 0:
                st.session_state["df_limpio"] = df_limpio
                logging.info("Datos limpios guardados en session_state")
            else:
                st.session_state["df_limpio"] = df
                logging.info("Datos originales guardados en session_state (sin limpieza)")
            
            # Option to run analysis on the cleaned data
            st.write(" *********************** ")
            st.markdown('<h4 class="custom-h4">An√°lisis y Modelado üìàüîç</h4>', unsafe_allow_html=True)
            
            if st.button("Ejecutar An√°lisis y Modelado"):
                logging.info("Iniciando proceso de an√°lisis y modelado")
                try:
                    # We'll use either the cleaned data or the original if no cleaning was done
                    if "df_limpio" in st.session_state:
                        logging.info("Ejecutando an√°lisis con los datos disponibles")
                        analysis.show_results()
                        logging.info("Proceso de an√°lisis y modelado completado")
                    else:
                        error_msg = "Datos no disponibles para an√°lisis"
                        st.error(f"‚ùå {error_msg}.")
                        logging.error(error_msg)
                except Exception as e:
                    error_msg = f"Error durante el an√°lisis: {str(e)}"
                    st.error(f"‚ùå {error_msg}")
                    logging.error(error_msg)
        except Exception as e:
            error_msg = f"Error general en la aplicaci√≥n: {e}"
            st.error(f"‚ùå {error_msg}")
            logging.error(error_msg)
            logging.error(f"Detalles del error:\n{str(e)}")
